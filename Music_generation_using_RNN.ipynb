{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ishikapachori/music-generation-using-rnn/blob/main/Music_generation_using_RNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "A55FHoEqMqt_",
        "outputId": "e2eca432-6099-4e4a-c825-04a673f53226"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing MIDI files: 100%|██████████| 3/3 [00:01<00:00,  1.84it/s]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ lstm (\u001b[38;5;33mLSTM\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m256\u001b[0m)        │       \u001b[38;5;34m264,192\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m256\u001b[0m)        │         \u001b[38;5;34m1,024\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m256\u001b[0m)        │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ lstm_1 (\u001b[38;5;33mLSTM\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │       \u001b[38;5;34m525,312\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_1           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │         \u001b[38;5;34m1,024\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │        \u001b[38;5;34m32,896\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ activation (\u001b[38;5;33mActivation\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_2           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │           \u001b[38;5;34m512\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_2 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m70\u001b[0m)             │         \u001b[38;5;34m9,030\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ activation_1 (\u001b[38;5;33mActivation\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m70\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)        │       <span style=\"color: #00af00; text-decoration-color: #00af00\">264,192</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)        │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ lstm_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">525,312</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_1           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">32,896</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ activation (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_2           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │           <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">70</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">9,030</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ activation_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">70</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m833,990\u001b[0m (3.18 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">833,990</span> (3.18 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m832,710\u001b[0m (3.18 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">832,710</span> (3.18 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m1,280\u001b[0m (5.00 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,280</span> (5.00 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/300\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 260ms/step - accuracy: 0.0108 - loss: 7.0706\n",
            "Epoch 1: accuracy improved from -inf to 0.02609, saving model to weights-improvement-01-0.0261.keras\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 345ms/step - accuracy: 0.0117 - loss: 7.0579 - val_accuracy: 0.0000e+00 - val_loss: 5.9127\n",
            "Epoch 2/300\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 267ms/step - accuracy: 0.0893 - loss: 6.0395\n",
            "Epoch 2: accuracy improved from 0.02609 to 0.07609, saving model to weights-improvement-02-0.0761.keras\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 325ms/step - accuracy: 0.0885 - loss: 6.0438 - val_accuracy: 0.0000e+00 - val_loss: 5.8818\n",
            "Epoch 3/300\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 282ms/step - accuracy: 0.0765 - loss: 5.8684\n",
            "Epoch 3: accuracy improved from 0.07609 to 0.07826, saving model to weights-improvement-03-0.0783.keras\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 308ms/step - accuracy: 0.0766 - loss: 5.8667 - val_accuracy: 0.0000e+00 - val_loss: 5.8542\n",
            "Epoch 4/300\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 263ms/step - accuracy: 0.0973 - loss: 5.8449\n",
            "Epoch 4: accuracy improved from 0.07826 to 0.11522, saving model to weights-improvement-04-0.1152.keras\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 288ms/step - accuracy: 0.0984 - loss: 5.8405 - val_accuracy: 0.0000e+00 - val_loss: 5.8073\n",
            "Epoch 5/300\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 353ms/step - accuracy: 0.1102 - loss: 5.5740\n",
            "Epoch 5: accuracy improved from 0.11522 to 0.11739, saving model to weights-improvement-05-0.1174.keras\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 378ms/step - accuracy: 0.1106 - loss: 5.5722 - val_accuracy: 0.0000e+00 - val_loss: 5.7419\n",
            "Epoch 6/300\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 262ms/step - accuracy: 0.1111 - loss: 5.5944\n",
            "Epoch 6: accuracy improved from 0.11739 to 0.12391, saving model to weights-improvement-06-0.1239.keras\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 293ms/step - accuracy: 0.1119 - loss: 5.5923 - val_accuracy: 0.0000e+00 - val_loss: 5.7510\n",
            "Epoch 7/300\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 292ms/step - accuracy: 0.1149 - loss: 5.4360\n",
            "Epoch 7: accuracy did not improve from 0.12391\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 311ms/step - accuracy: 0.1151 - loss: 5.4319 - val_accuracy: 0.0000e+00 - val_loss: 5.7775\n",
            "Epoch 8/300\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 258ms/step - accuracy: 0.1007 - loss: 5.3919\n",
            "Epoch 8: accuracy did not improve from 0.12391\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 279ms/step - accuracy: 0.1022 - loss: 5.3849 - val_accuracy: 0.0000e+00 - val_loss: 5.7937\n",
            "Epoch 9/300\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 347ms/step - accuracy: 0.1450 - loss: 5.2990\n",
            "Epoch 9: accuracy improved from 0.12391 to 0.13696, saving model to weights-improvement-09-0.1370.keras\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 373ms/step - accuracy: 0.1445 - loss: 5.2994 - val_accuracy: 0.0000e+00 - val_loss: 5.7957\n",
            "Epoch 10/300\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 262ms/step - accuracy: 0.1108 - loss: 5.2544\n",
            "Epoch 10: accuracy did not improve from 0.13696\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 282ms/step - accuracy: 0.1108 - loss: 5.2503 - val_accuracy: 0.0000e+00 - val_loss: 5.8143\n",
            "Epoch 11/300\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 310ms/step - accuracy: 0.1197 - loss: 5.2914\n",
            "Epoch 11: accuracy did not improve from 0.13696\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 335ms/step - accuracy: 0.1200 - loss: 5.2866 - val_accuracy: 0.0000e+00 - val_loss: 5.7678\n",
            "Epoch 12/300\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 343ms/step - accuracy: 0.0848 - loss: 5.1942\n",
            "Epoch 12: accuracy did not improve from 0.13696\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 362ms/step - accuracy: 0.0864 - loss: 5.1911 - val_accuracy: 0.0000e+00 - val_loss: 5.7802\n",
            "Epoch 13/300\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 263ms/step - accuracy: 0.1389 - loss: 5.0322\n",
            "Epoch 13: accuracy improved from 0.13696 to 0.13913, saving model to weights-improvement-13-0.1391.keras\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 294ms/step - accuracy: 0.1389 - loss: 5.0306 - val_accuracy: 0.0000e+00 - val_loss: 5.7664\n",
            "Epoch 14/300\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 263ms/step - accuracy: 0.1136 - loss: 4.9572\n",
            "Epoch 14: accuracy did not improve from 0.13913\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 289ms/step - accuracy: 0.1138 - loss: 4.9523 - val_accuracy: 0.0000e+00 - val_loss: 5.6784\n",
            "Epoch 15/300\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 358ms/step - accuracy: 0.1442 - loss: 5.0387\n",
            "Epoch 15: accuracy improved from 0.13913 to 0.15000, saving model to weights-improvement-15-0.1500.keras\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 389ms/step - accuracy: 0.1446 - loss: 5.0346 - val_accuracy: 0.0000e+00 - val_loss: 5.6843\n",
            "Epoch 16/300\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 348ms/step - accuracy: 0.1265 - loss: 4.8407\n",
            "Epoch 16: accuracy did not improve from 0.15000\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 367ms/step - accuracy: 0.1258 - loss: 4.8426 - val_accuracy: 0.0000e+00 - val_loss: 5.7569\n",
            "Epoch 17/300\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 262ms/step - accuracy: 0.1266 - loss: 4.9104\n",
            "Epoch 17: accuracy did not improve from 0.15000\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 282ms/step - accuracy: 0.1278 - loss: 4.9036 - val_accuracy: 0.0000e+00 - val_loss: 5.8719\n",
            "Epoch 18/300\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 263ms/step - accuracy: 0.1440 - loss: 4.7987\n",
            "Epoch 18: accuracy did not improve from 0.15000\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 282ms/step - accuracy: 0.1443 - loss: 4.7989 - val_accuracy: 0.0000e+00 - val_loss: 5.9552\n",
            "Epoch 19/300\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 291ms/step - accuracy: 0.1812 - loss: 4.8013\n",
            "Epoch 19: accuracy improved from 0.15000 to 0.16957, saving model to weights-improvement-19-0.1696.keras\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 323ms/step - accuracy: 0.1805 - loss: 4.8039 - val_accuracy: 0.0000e+00 - val_loss: 5.7112\n",
            "Epoch 20/300\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 264ms/step - accuracy: 0.1277 - loss: 4.7731\n",
            "Epoch 20: accuracy did not improve from 0.16957\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 284ms/step - accuracy: 0.1281 - loss: 4.7698 - val_accuracy: 0.0000e+00 - val_loss: 5.4628\n",
            "Epoch 21/300\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 359ms/step - accuracy: 0.1584 - loss: 4.6944\n",
            "Epoch 21: accuracy did not improve from 0.16957\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 379ms/step - accuracy: 0.1588 - loss: 4.6909 - val_accuracy: 0.0000e+00 - val_loss: 5.5295\n",
            "Epoch 22/300\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 261ms/step - accuracy: 0.1214 - loss: 4.7219\n",
            "Epoch 22: accuracy did not improve from 0.16957\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 286ms/step - accuracy: 0.1225 - loss: 4.7181 - val_accuracy: 0.0000e+00 - val_loss: 5.5201\n",
            "Epoch 23/300\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 262ms/step - accuracy: 0.1673 - loss: 4.5075\n",
            "Epoch 23: accuracy did not improve from 0.16957\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 287ms/step - accuracy: 0.1668 - loss: 4.5079 - val_accuracy: 0.0087 - val_loss: 5.6166\n",
            "Epoch 24/300\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 318ms/step - accuracy: 0.1526 - loss: 4.4581\n",
            "Epoch 24: accuracy did not improve from 0.16957\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 343ms/step - accuracy: 0.1512 - loss: 4.4623 - val_accuracy: 0.0696 - val_loss: 5.4145\n",
            "Epoch 25/300\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 344ms/step - accuracy: 0.1673 - loss: 4.5292\n",
            "Epoch 25: accuracy did not improve from 0.16957\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 364ms/step - accuracy: 0.1666 - loss: 4.5302 - val_accuracy: 0.0174 - val_loss: 5.0101\n",
            "Epoch 26/300\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 261ms/step - accuracy: 0.0990 - loss: 4.4883\n",
            "Epoch 26: accuracy did not improve from 0.16957\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 285ms/step - accuracy: 0.0999 - loss: 4.4933 - val_accuracy: 0.1217 - val_loss: 4.8545\n",
            "Epoch 27/300\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 304ms/step - accuracy: 0.1487 - loss: 4.4769\n",
            "Epoch 27: accuracy did not improve from 0.16957\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 323ms/step - accuracy: 0.1480 - loss: 4.4826 - val_accuracy: 0.0348 - val_loss: 5.0115\n",
            "Epoch 28/300\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 262ms/step - accuracy: 0.1518 - loss: 4.3364\n",
            "Epoch 28: accuracy did not improve from 0.16957\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 287ms/step - accuracy: 0.1517 - loss: 4.3379 - val_accuracy: 0.0000e+00 - val_loss: 5.3429\n",
            "Epoch 29/300\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 339ms/step - accuracy: 0.1548 - loss: 4.3011\n",
            "Epoch 29: accuracy did not improve from 0.16957\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 363ms/step - accuracy: 0.1546 - loss: 4.3045 - val_accuracy: 0.0957 - val_loss: 5.3557\n",
            "Epoch 30/300\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 265ms/step - accuracy: 0.1688 - loss: 4.2344\n",
            "Epoch 30: accuracy did not improve from 0.16957\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 284ms/step - accuracy: 0.1682 - loss: 4.2342 - val_accuracy: 0.1130 - val_loss: 5.2089\n",
            "Epoch 31/300\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 341ms/step - accuracy: 0.1630 - loss: 4.1739\n",
            "Epoch 31: accuracy did not improve from 0.16957\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 361ms/step - accuracy: 0.1629 - loss: 4.1735 - val_accuracy: 0.1304 - val_loss: 5.0811\n",
            "Epoch 32/300\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 264ms/step - accuracy: 0.1309 - loss: 4.2428\n",
            "Epoch 32: accuracy did not improve from 0.16957\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 289ms/step - accuracy: 0.1331 - loss: 4.2427 - val_accuracy: 0.1217 - val_loss: 5.0599\n",
            "Epoch 33/300\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 272ms/step - accuracy: 0.1794 - loss: 4.2700\n",
            "Epoch 33: accuracy did not improve from 0.16957\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 321ms/step - accuracy: 0.1785 - loss: 4.2674 - val_accuracy: 0.1217 - val_loss: 4.9120\n",
            "Epoch 34/300\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 278ms/step - accuracy: 0.1995 - loss: 4.0018\n",
            "Epoch 34: accuracy improved from 0.16957 to 0.17826, saving model to weights-improvement-34-0.1783.keras\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 304ms/step - accuracy: 0.1981 - loss: 4.0110 - val_accuracy: 0.0870 - val_loss: 4.9069\n",
            "Epoch 35/300\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 260ms/step - accuracy: 0.1644 - loss: 4.0854\n",
            "Epoch 35: accuracy did not improve from 0.17826\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 285ms/step - accuracy: 0.1647 - loss: 4.0878 - val_accuracy: 0.0957 - val_loss: 4.7217\n",
            "Epoch 36/300\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 343ms/step - accuracy: 0.1927 - loss: 4.0831\n",
            "Epoch 36: accuracy did not improve from 0.17826\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 368ms/step - accuracy: 0.1916 - loss: 4.0876 - val_accuracy: 0.0957 - val_loss: 4.5861\n",
            "Epoch 37/300\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 263ms/step - accuracy: 0.1816 - loss: 3.8869\n",
            "Epoch 37: accuracy did not improve from 0.17826\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 288ms/step - accuracy: 0.1811 - loss: 3.8951 - val_accuracy: 0.1130 - val_loss: 4.5948\n",
            "Epoch 38/300\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 312ms/step - accuracy: 0.1919 - loss: 3.9782\n",
            "Epoch 38: accuracy improved from 0.17826 to 0.18696, saving model to weights-improvement-38-0.1870.keras\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 352ms/step - accuracy: 0.1916 - loss: 3.9779 - val_accuracy: 0.0870 - val_loss: 4.8820\n",
            "Epoch 39/300\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import glob\n",
        "import os\n",
        "from music21 import converter, instrument, note, chord, stream\n",
        "from tensorflow.keras.layers import LSTM, Dense, Dropout, Activation, BatchNormalization, Input\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.regularizers import l2\n",
        "import matplotlib.pyplot as plt\n",
        "import pickle\n",
        "import random\n",
        "from tqdm import tqdm\n",
        "from google.colab import files\n",
        "\n",
        "# Clear GPU memory\n",
        "tf.keras.backend.clear_session()\n",
        "\n",
        "# Step 1: Data Preparation\n",
        "def extract_notes_from_midi(file_path):\n",
        "    \"\"\"Extract all notes and chords from a MIDI file.\"\"\"\n",
        "    try:\n",
        "        midi = converter.parse(file_path)\n",
        "        notes_to_parse = None\n",
        "\n",
        "        # Handle multi-instrument files by selecting only one instrument\n",
        "        try:\n",
        "            s2 = instrument.partitionByInstrument(midi)\n",
        "            notes_to_parse = s2.parts[0].recurse()\n",
        "        except:\n",
        "            notes_to_parse = midi.flat.notes\n",
        "\n",
        "        notes = []\n",
        "        for element in notes_to_parse:\n",
        "            if isinstance(element, note.Note):\n",
        "                notes.append(str(element.pitch))\n",
        "            elif isinstance(element, chord.Chord):\n",
        "                notes.append('.'.join(str(n) for n in element.normalOrder))\n",
        "\n",
        "        return notes\n",
        "    except Exception as e:\n",
        "        print(f\"Error processing {file_path}: {e}\")\n",
        "        return []\n",
        "\n",
        "def prepare_sequences(notes, sequence_length=30):  # Reduced sequence length\n",
        "    \"\"\"Prepare the sequences used for the model.\"\"\"\n",
        "    # Get all pitch names\n",
        "    pitchnames = sorted(set(notes))\n",
        "\n",
        "    # Create a dictionary to map pitches to integers\n",
        "    note_to_int = dict((note, number) for number, note in enumerate(pitchnames))\n",
        "\n",
        "    network_input = []\n",
        "    network_output = []\n",
        "\n",
        "    # Create input sequences and the corresponding outputs\n",
        "    for i in range(0, len(notes) - sequence_length):\n",
        "        sequence_in = notes[i:i + sequence_length]\n",
        "        sequence_out = notes[i + sequence_length]\n",
        "        network_input.append([note_to_int[char] for char in sequence_in])\n",
        "        network_output.append(note_to_int[sequence_out])\n",
        "\n",
        "    # Reshape the input into a format compatible with LSTM layers\n",
        "    n_patterns = len(network_input)\n",
        "    n_vocab = len(pitchnames)\n",
        "\n",
        "    network_input = np.reshape(network_input, (n_patterns, sequence_length))\n",
        "\n",
        "    # Normalize input\n",
        "    network_input = network_input / float(n_vocab)\n",
        "\n",
        "    # One-hot encode the output\n",
        "    network_output = tf.keras.utils.to_categorical(network_output, num_classes=n_vocab)\n",
        "\n",
        "    return (network_input, network_output, n_vocab, pitchnames, note_to_int)\n",
        "\n",
        "# Step 2: Build the RNN Model\n",
        "def build_model(network_input, n_vocab, sequence_length=30):  # Reduced sequence length\n",
        "    \"\"\"Build the LSTM model.\"\"\"\n",
        "    model = tf.keras.Sequential([\n",
        "        Input(shape=(sequence_length, 1)),\n",
        "        LSTM(256, return_sequences=True, recurrent_dropout=0.2),\n",
        "        BatchNormalization(),\n",
        "        Dropout(0.5),\n",
        "        LSTM(256),\n",
        "        BatchNormalization(),\n",
        "        Dropout(0.5),\n",
        "        Dense(128, kernel_regularizer=l2(0.01)),\n",
        "        Activation('relu'),\n",
        "        BatchNormalization(),\n",
        "        Dropout(0.5),\n",
        "        Dense(n_vocab),\n",
        "        Activation('softmax')\n",
        "    ])\n",
        "\n",
        "    optimizer = Adam(learning_rate=0.0005)  # Adjusted learning rate\n",
        "    model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
        "\n",
        "    return model\n",
        "\n",
        "# Step 3: Train the Model\n",
        "def train_model(model, network_input, network_output, epochs=300, batch_size=32):  # Increased epochs\n",
        "    \"\"\"Train the neural network.\"\"\"\n",
        "    filepath = \"weights-improvement-{epoch:02d}-{accuracy:.4f}.keras\"\n",
        "    checkpoint = ModelCheckpoint(\n",
        "        filepath,\n",
        "        monitor='accuracy',\n",
        "        verbose=1,\n",
        "        save_best_only=True,\n",
        "        mode='max'\n",
        "    )\n",
        "    callbacks_list = [checkpoint]\n",
        "\n",
        "    # Reshape input to be [samples, time steps, features]\n",
        "    network_input = np.reshape(network_input, (len(network_input), network_input.shape[1], 1))\n",
        "\n",
        "    history = model.fit(\n",
        "        network_input,\n",
        "        network_output,\n",
        "        epochs=epochs,\n",
        "        batch_size=batch_size,\n",
        "        callbacks=callbacks_list,\n",
        "        validation_split=0.2\n",
        "    )\n",
        "\n",
        "    return model, history\n",
        "\n",
        "# Step 4: Generate Music\n",
        "def generate_notes(model, network_input, pitchnames, note_to_int, n_vocab, num_notes=500, temperature=1.0):\n",
        "    \"\"\"Generate notes using the trained model.\"\"\"\n",
        "    # Pick a random sequence from the input as a starting point for the prediction\n",
        "    start = np.random.randint(0, len(network_input)-1)\n",
        "    pattern = network_input[start]\n",
        "    prediction_output = []\n",
        "\n",
        "    # Generate notes\n",
        "    for note_index in tqdm(range(num_notes)):\n",
        "        # Reshape the pattern to match the input shape of the model\n",
        "        x = np.reshape(pattern, (1, len(pattern), 1))\n",
        "        x = x / float(n_vocab)\n",
        "\n",
        "        # Make a prediction\n",
        "        prediction = model.predict(x, verbose=0)[0]\n",
        "\n",
        "        # Apply temperature to adjust the randomness of the prediction\n",
        "        prediction = np.log(prediction + 1e-10) / temperature\n",
        "        exp_preds = np.exp(prediction)\n",
        "        prediction = exp_preds / np.sum(exp_preds)\n",
        "\n",
        "        # Convert the prediction into an integer index\n",
        "        index = np.random.choice(range(len(prediction)), p=prediction)\n",
        "\n",
        "        # Map the index to the actual note\n",
        "        result = pitchnames[index]\n",
        "        prediction_output.append(result)\n",
        "\n",
        "        # Update pattern by removing the first element and adding the predicted index\n",
        "        pattern = np.append(pattern[1:], index / float(n_vocab))\n",
        "\n",
        "    return prediction_output\n",
        "\n",
        "def create_midi(prediction_output, filename=\"generated_music.mid\"):\n",
        "    \"\"\"Convert the predicted notes into a MIDI file.\"\"\"\n",
        "    offset = 0\n",
        "    output_notes = []\n",
        "\n",
        "    # Create note and chord objects based on the values generated\n",
        "    for pattern in prediction_output:\n",
        "        # Pattern is a chord\n",
        "        if ('.' in pattern) or pattern.isdigit():\n",
        "            notes_in_chord = pattern.split('.')\n",
        "            notes = []\n",
        "            for current_note in notes_in_chord:\n",
        "                new_note = note.Note(int(current_note))\n",
        "                new_note.storedInstrument = instrument.Piano()\n",
        "                notes.append(new_note)\n",
        "            new_chord = chord.Chord(notes)\n",
        "            new_chord.offset = offset\n",
        "            output_notes.append(new_chord)\n",
        "        # Pattern is a note\n",
        "        else:\n",
        "            new_note = note.Note(pattern)\n",
        "            new_note.offset = offset\n",
        "            new_note.storedInstrument = instrument.Piano()\n",
        "            output_notes.append(new_note)\n",
        "\n",
        "        # Increase offset each iteration so notes don't stack\n",
        "        offset += 0.5\n",
        "\n",
        "    midi_stream = stream.Stream(output_notes)\n",
        "    midi_stream.write('midi', fp=filename)\n",
        "    print(f\"MIDI file saved at: {os.path.abspath(filename)}\")  # Debug statement\n",
        "\n",
        "def evaluate_model(model, test_input, test_output):\n",
        "    \"\"\"Evaluate model accuracy on test data.\"\"\"\n",
        "    test_input = np.reshape(test_input, (len(test_input), test_input.shape[1], 1))\n",
        "    test_loss, test_accuracy = model.evaluate(test_input, test_output)\n",
        "    return test_loss, test_accuracy\n",
        "\n",
        "def plot_training_history(history):\n",
        "    \"\"\"Plot the training history.\"\"\"\n",
        "    plt.figure(figsize=(12, 5))\n",
        "\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.plot(history.history['accuracy'])\n",
        "    plt.plot(history.history['val_accuracy'])\n",
        "    plt.title('Model Accuracy')\n",
        "    plt.ylabel('Accuracy')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.legend(['Train', 'Validation'], loc='lower right')\n",
        "\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.plot(history.history['loss'])\n",
        "    plt.plot(history.history['val_loss'])\n",
        "    plt.title('Model Loss')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.legend(['Train', 'Validation'], loc='upper right')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.savefig('training_history.png')\n",
        "    plt.show()\n",
        "\n",
        "# Main function to run the entire pipeline\n",
        "def main():\n",
        "    # Step 1: Get all MIDI files\n",
        "    midi_files = glob.glob(\"midi_songs/*.mid\")\n",
        "\n",
        "    if not midi_files:\n",
        "        print(\"No MIDI files found. Please place MIDI files in a directory named 'midi_songs'\")\n",
        "        return\n",
        "\n",
        "    # Extract notes from MIDI files\n",
        "    notes = []\n",
        "    for file in tqdm(midi_files, desc=\"Processing MIDI files\"):\n",
        "        notes_from_file = extract_notes_from_midi(file)\n",
        "        notes.extend(notes_from_file)\n",
        "\n",
        "    # Save notes to file for later use\n",
        "    os.makedirs(\"data\", exist_ok=True)\n",
        "    with open('data/notes', 'wb') as filepath:\n",
        "        pickle.dump(notes, filepath)\n",
        "\n",
        "    # Step 2: Prepare sequences\n",
        "    sequence_length = 30  # Reduced sequence length\n",
        "    network_input, network_output, n_vocab, pitchnames, note_to_int = prepare_sequences(notes, sequence_length)\n",
        "\n",
        "    # Save pitch names and note to int mapping for later use\n",
        "    with open('data/pitchnames', 'wb') as filepath:\n",
        "        pickle.dump(pitchnames, filepath)\n",
        "    with open('data/note_to_int', 'wb') as filepath:\n",
        "        pickle.dump(note_to_int, filepath)\n",
        "\n",
        "    # Step 3: Build the model\n",
        "    model = build_model(network_input, n_vocab, sequence_length)\n",
        "    model.summary()\n",
        "\n",
        "    # Step 4: Train the model\n",
        "    model, history = train_model(model, network_input, network_output, epochs=300, batch_size=32)  # Increased epochs\n",
        "\n",
        "    # Save the model\n",
        "    model.save('trained_model.keras')\n",
        "\n",
        "    # Plot training history\n",
        "    plot_training_history(history)\n",
        "\n",
        "    # Evaluate model\n",
        "    # Split off test data\n",
        "    test_size = int(len(network_input) * 0.2)\n",
        "    test_input = network_input[-test_size:]\n",
        "    test_output = network_output[-test_size:]\n",
        "\n",
        "    test_loss, test_accuracy = evaluate_model(model, test_input, test_output)\n",
        "    print(f\"Test accuracy: {test_accuracy*100:.2f}%\")\n",
        "\n",
        "    # Generate music unconditionally\n",
        "    print(\"Generating music...\")\n",
        "    prediction_output = generate_notes(model, network_input, pitchnames, note_to_int, n_vocab, num_notes=500)\n",
        "    create_midi(prediction_output, \"generated_music.mid\")\n",
        "    print(\"Music generated and saved as 'generated_music.mid'\")\n",
        "\n",
        "    # Provide download link for the generated MIDI file\n",
        "    print(\"Download the generated music file:\")\n",
        "    files.download(\"generated_music.mid\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # Create necessary directories\n",
        "    os.makedirs(\"midi_songs\", exist_ok=True)\n",
        "    os.makedirs(\"data\", exist_ok=True)\n",
        "\n",
        "    main()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}